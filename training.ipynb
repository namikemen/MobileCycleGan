{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import color\n",
    "import numpy as np\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "\n",
    "from utils import *\n",
    "from generator import *\n",
    "from loss import *\n",
    "from block import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_criterion = nn.MSELoss() \n",
    "recon_criterion = nn.L1Loss() \n",
    "\n",
    "n_epochs = 100\n",
    "dim_A = 3\n",
    "dim_B = 3\n",
    "display_step = 200\n",
    "batch_size = 1\n",
    "lr = 0.0002\n",
    "load_shape = 286\n",
    "target_shape = 256\n",
    "device = 'mps'\n",
    "hidden_dim = 64\n",
    "expand_ratio = 4\n",
    "\n",
    "data_path = \"Monet2Photo\"\n",
    "\n",
    "pretrained = False\n",
    "save_model = False\n",
    "\n",
    "version = 'v1'\n",
    "\n",
    "loss_path = f'{version}_loss.csv'\n",
    "weights_path = f'cycleGAN_{version}_100000.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 130\u001b[0m\n\u001b[1;32m    128\u001b[0m                     df\u001b[39m.\u001b[39mto_csv(loss_path, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    129\u001b[0m             cur_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 130\u001b[0m train()\n",
      "Cell \u001b[0;32mIn[3], line 98\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(save_model, cur_step)\u001b[0m\n\u001b[1;32m     94\u001b[0m gen_opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     95\u001b[0m gen_loss, fake_A, fake_B \u001b[39m=\u001b[39m get_gen_loss(\n\u001b[1;32m     96\u001b[0m     real_A, real_B, gen_AB, gen_BA, disc_A, disc_B, adv_criterion, recon_criterion, recon_criterion\n\u001b[1;32m     97\u001b[0m )\n\u001b[0;32m---> 98\u001b[0m gen_loss\u001b[39m.\u001b[39;49mbackward() \u001b[39m# Update gradients\u001b[39;00m\n\u001b[1;32m     99\u001b[0m gen_opt\u001b[39m.\u001b[39mstep() \u001b[39m# Update optimizer\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m# Keep track of the average discriminator loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if version == 'v0': block = ResnetBlock\n",
    "if version == 'v1': block = InvertedBlock\n",
    "if version == 'v2': block = ResidualBlock\n",
    "\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(load_shape),\n",
    "    transforms.RandomCrop(target_shape),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageDataset(data_path, transform=transform)\n",
    "\n",
    "#Initialize\n",
    "gen_AB = Generator(dim_A, dim_B, block, hidden_dim, expand_ratio).to(device)\n",
    "gen_BA = Generator(dim_B, dim_A, block, hidden_dim, expand_ratio).to(device)\n",
    "gen_opt = torch.optim.Adam(list(gen_AB.parameters()) + list(gen_BA.parameters()), lr=lr, betas=(0.5, 0.999))\n",
    "disc_A = Discriminator(dim_A).to(device)\n",
    "disc_A_opt = torch.optim.Adam(disc_A.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "disc_B = Discriminator(dim_B).to(device)\n",
    "disc_B_opt = torch.optim.Adam(disc_B.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# load model\n",
    "if pretrained:\n",
    "    pre_dict = torch.load(weights_path)\n",
    "    gen_AB.load_state_dict(pre_dict['gen_AB'])\n",
    "    gen_BA.load_state_dict(pre_dict['gen_BA'])\n",
    "    gen_opt.load_state_dict(pre_dict['gen_opt'])\n",
    "    disc_A.load_state_dict(pre_dict['disc_A'])\n",
    "    disc_A_opt.load_state_dict(pre_dict['disc_A_opt'])\n",
    "    disc_B.load_state_dict(pre_dict['disc_B'])\n",
    "    disc_B_opt.load_state_dict(pre_dict['disc_B_opt'])\n",
    "    generator_loss, discriminator_loss, step = pd.read_csv(loss_path).values.tolist()\n",
    "    cur_step = int(step[0])\n",
    "else:\n",
    "    gen_AB = gen_AB.apply(weights_init)\n",
    "    gen_BA = gen_BA.apply(weights_init)\n",
    "    disc_A = disc_A.apply(weights_init)\n",
    "    disc_B = disc_B.apply(weights_init)\n",
    "    generator_loss = []\n",
    "    discriminator_loss = []\n",
    "    cur_step = 0\n",
    "    \n",
    "\n",
    "def train(save_model=save_model, cur_step=cur_step):\n",
    "    mean_generator_loss = 0\n",
    "    mean_discriminator_loss = 0\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Dataloader returns the batches\n",
    "        # for image, _ in tqdm(dataloader):\n",
    "        for real_A, real_B in tqdm(dataloader):\n",
    "            # image_width = image.shape[3]\n",
    "            real_A = nn.functional.interpolate(real_A, size=target_shape)\n",
    "            real_B = nn.functional.interpolate(real_B, size=target_shape)\n",
    "            cur_batch_size = len(real_A)\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "\n",
    "            ### Update discriminator A ###\n",
    "            disc_A_opt.zero_grad() # Zero out the gradient before backpropagation\n",
    "            with torch.no_grad():\n",
    "                fake_A = gen_BA(real_B)\n",
    "            disc_A_loss = get_disc_loss(real_A, fake_A, disc_A, adv_criterion)\n",
    "            disc_A_loss.backward(retain_graph=True) # Update gradients\n",
    "            disc_A_opt.step() # Update optimizer\n",
    "\n",
    "            ### Update discriminator B ###\n",
    "            disc_B_opt.zero_grad() # Zero out the gradient before backpropagation\n",
    "            with torch.no_grad():\n",
    "                fake_B = gen_AB(real_A)\n",
    "            disc_B_loss = get_disc_loss(real_B, fake_B, disc_B, adv_criterion)\n",
    "            disc_B_loss.backward(retain_graph=True) # Update gradients\n",
    "            disc_B_opt.step() # Update optimizer\n",
    "\n",
    "            ### Update generator ###\n",
    "            gen_opt.zero_grad()\n",
    "            gen_loss, fake_A, fake_B = get_gen_loss(\n",
    "                real_A, real_B, gen_AB, gen_BA, disc_A, disc_B, adv_criterion, recon_criterion, recon_criterion\n",
    "            )\n",
    "            gen_loss.backward() # Update gradients\n",
    "            gen_opt.step() # Update optimizer\n",
    "\n",
    "            # Keep track of the average discriminator loss\n",
    "            mean_discriminator_loss += disc_A_loss.item() / display_step\n",
    "            # Keep track of the average generator loss\n",
    "            mean_generator_loss += gen_loss.item() / display_step\n",
    "\n",
    "            ### Visualization code ###\n",
    "            if cur_step % display_step == 0:\n",
    "                print(f\"Epoch {epoch}: Step {cur_step}: Generator (U-Net) loss: {mean_generator_loss}, Discriminator loss: {mean_discriminator_loss}\")\n",
    "                show_tensor_images(torch.cat([real_A, real_B]), size=(dim_A, target_shape, target_shape))\n",
    "                show_tensor_images(torch.cat([fake_B, fake_A]), size=(dim_B, target_shape, target_shape))\n",
    "                generator_loss.append(mean_generator_loss)\n",
    "                discriminator_loss.append(mean_discriminator_loss)\n",
    "                mean_generator_loss = 0\n",
    "                mean_discriminator_loss = 0\n",
    "\n",
    "                if save_model:\n",
    "                    torch.save({\n",
    "                        'gen_AB': gen_AB.state_dict(),\n",
    "                        'gen_BA': gen_BA.state_dict(),\n",
    "                        'gen_opt': gen_opt.state_dict(),\n",
    "                        'disc_A': disc_A.state_dict(),\n",
    "                        'disc_A_opt': disc_A_opt.state_dict(),\n",
    "                        'disc_B': disc_B.state_dict(),\n",
    "                        'disc_B_opt': disc_B_opt.state_dict()\n",
    "                    }, f\"cycleGAN_{version}_{cur_step}.pth\")\n",
    "\n",
    "                    df = pd.DataFrame([generator_loss, discriminator_loss,[cur_step]]) \n",
    "                    df.to_csv(loss_path, index=False)\n",
    "            cur_step += 1\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21dd95685b54141badc16ffafb84bdd59df20856a66198ee8e70fe23de69c9a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
